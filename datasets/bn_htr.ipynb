{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the following params correctly\n",
    "* **data_path**  : Path to The folder that contains **1 to 150** folders \n",
    "* **save_path**  : Path to save the processed data\n",
    "* **split_test** : %of test data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"/media/ansary/DriveData/Work/bengalAI/datasets/__raw__/Dataset\"\n",
    "save_path=\"/media/ansary/DriveData/Work/bengalAI/datasets/Recognition/\"\n",
    "split_test=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "#--------------------\n",
    "# imports\n",
    "#--------------------\n",
    "import os \n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import string\n",
    "import random\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "from shutil import copyfile\n",
    "from PIL import Image, ImageEnhance                                                                \n",
    "from coreLib.utils import stripPads,LOG_INFO,GraphemeParser,create_dir,WordCleaner\n",
    "tqdm.pandas()\n",
    "random.seed(42)\n",
    "assert len(os.listdir(data_path))==150,\"WORNG data_path for folders\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs=[]\n",
    "#---------------------\n",
    "# process xlsx\n",
    "#---------------------\n",
    "for i in tqdm(range(1,151)):\n",
    "    xlsx=os.path.join(data_path,f\"{i}\",f\"{i}.xlsx\")\n",
    "    df=pd.read_excel(xlsx)\n",
    "    if \"Id\" in df.columns:\n",
    "        filename=df[\"Id\"].tolist()\n",
    "    else:\n",
    "        filename=df[\"ID\"].tolist()\n",
    "\n",
    "    if \"Word\" in df.columns:\n",
    "        labels=df[\"Word\"].tolist()\n",
    "    else:\n",
    "        labels=df[\"word\"].tolist()\n",
    "\n",
    "    df=pd.DataFrame({\"mode\":filename,\"word\":labels})\n",
    "    dfs.append(df)\n",
    "df=pd.concat(dfs,ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------\n",
    "# graphemes and cleaning\n",
    "#----------------------------\n",
    "GP=GraphemeParser()\n",
    "WC=WordCleaner()\n",
    "df.word=df.word.progress_apply(lambda x: WC.clean(str(x)))\n",
    "df.dropna(inplace=True)\n",
    "df[\"graphemes\"]=df.word.progress_apply(lambda x: GP.word2grapheme(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------\n",
    "# valid images\n",
    "#----------------------------\n",
    "idens=df[\"mode\"].tolist()\n",
    "valid=[]\n",
    "for i in tqdm(range(1,151)):\n",
    "    folder=os.path.join(data_path,f\"{i}\",\"Words\")\n",
    "    img_paths=[img_path for img_path in glob(os.path.join(folder,\"*/*.*\"))]\n",
    "    for src in img_paths:\n",
    "        base=os.path.basename(src).split(\".\")[0]\n",
    "        if base in idens:\n",
    "            valid.append(src)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path=create_dir(save_path,\"bh\")\n",
    "save_path=create_dir(main_path,\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeShadow(img):\n",
    "    rgb_planes = cv2.split(img)\n",
    "\n",
    "    result_planes = []\n",
    "    result_norm_planes = []\n",
    "    for plane in rgb_planes:\n",
    "        dilated_img = cv2.dilate(plane, np.ones((7,7), np.uint8))\n",
    "        bg_img = cv2.medianBlur(dilated_img, 21)\n",
    "        diff_img = 255 - cv2.absdiff(plane, bg_img)\n",
    "        norm_img = cv2.normalize(diff_img,None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\n",
    "        result_planes.append(diff_img)\n",
    "        result_norm_planes.append(norm_img)\n",
    "\n",
    "    result = cv2.merge(result_planes)\n",
    "    result_norm = cv2.merge(result_norm_planes)\n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iden=0\n",
    "\n",
    "filename=[]\n",
    "word=[]\n",
    "graphemes=[]\n",
    "mode=[]\n",
    "\n",
    "for img_path in tqdm(valid):\n",
    "    img=cv2.imread(img_path)\n",
    "    # base\n",
    "    base=os.path.basename(img_path).split(\".\")[0]\n",
    "    idf=df.loc[df[\"mode\"]==base]\n",
    "    _word=idf.word.tolist()[0]\n",
    "    _graphemes=idf.graphemes.tolist()[0]\n",
    "    _mode=idf[\"mode\"].tolist()[0].split(\"_\")[0]\n",
    "    fname=f\"{iden}.png\"\n",
    "    \n",
    "    cv2.imwrite(os.path.join(save_path,fname),img)\n",
    "    filename.append(fname)\n",
    "    word.append(_word)\n",
    "    graphemes.append(_graphemes)\n",
    "    mode.append(_mode)\n",
    "    \n",
    "    iden+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  =   pd.DataFrame({\"filename\":filename,\n",
    "                      \"word\":word,\n",
    "                      \"graphemes\":graphemes,\n",
    "                      \"mode\":mode})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)\n",
    "\n",
    "# test train split\n",
    "srcs=list(data[\"mode\"].unique())\n",
    "random.shuffle(srcs)\n",
    "eval_len=int(len(srcs)*split_test/100)\n",
    "eval_srcs=srcs[:eval_len]\n",
    "data[\"mode\"]=data[\"mode\"].progress_apply(lambda x: \"test\" if x in eval_srcs else \"train\")\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(os.path.join(main_path,\"data.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_INFO(f\"IMPORTANT: PATH TO USE FOR tools/process.py:{main_path}\",\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bangla",
   "language": "python",
   "name": "bangla"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
