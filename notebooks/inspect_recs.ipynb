{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2b161ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/ansary/WORK/Work/APSIS/datasets/Recognition/datasets/bw/temp/tfrecord/2.tfrecord', '/home/ansary/WORK/Work/APSIS/datasets/Recognition/datasets/bw/temp/tfrecord/0.tfrecord', '/home/ansary/WORK/Work/APSIS/datasets/Recognition/datasets/bw/temp/tfrecord/1.tfrecord']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import os\n",
    "from glob import glob\n",
    "pos_max=40\n",
    "nb_channels=3\n",
    "img_height,img_width=64,512\n",
    "factor=32\n",
    "BATCH_SIZE=32\n",
    "def data_input_fn(recs,mode): \n",
    "    '''\n",
    "      This Function generates data from gcs\n",
    "      * The parser function should look similiar now because of datasetEDA\n",
    "    '''\n",
    "    def _parser(example):   \n",
    "        feature ={  'image'  : tf.io.FixedLenFeature([],tf.string) ,\n",
    "                    'mask'   : tf.io.FixedLenFeature([],tf.string) ,\n",
    "                    'label'  : tf.io.FixedLenFeature([pos_max],tf.int64)\n",
    "                            }    \n",
    "        parsed_example=tf.io.parse_single_example(example,feature)\n",
    "        # image\n",
    "        image_raw=parsed_example['image']\n",
    "        image=tf.image.decode_png(image_raw,channels=nb_channels)\n",
    "        image=tf.cast(image,tf.float32)/255.0\n",
    "        image=tf.reshape(image,(img_height,img_width,nb_channels))\n",
    "        \n",
    "        # mask\n",
    "        mask_raw=parsed_example['mask']\n",
    "        mask=tf.image.decode_png(mask_raw,channels=1)\n",
    "        mask=tf.cast(mask,tf.float32)\n",
    "        mask=tf.reshape(mask,(img_height,img_width,nb_channels))\n",
    "        mask=tf.image.resize(mask,[img_height//factor,img_width//factor],\"nearest\")\n",
    "        \n",
    "        # label\n",
    "        label=parsed_example['label']\n",
    "            \n",
    "        # position\n",
    "        pos=tf.range(0,pos_max)\n",
    "        pos=tf.cast(pos,tf.int32)\n",
    "        \n",
    "        return {\"image\":image,\"label\":tf.cast(label, tf.int32),\"pos\":pos,\"mask\":mask},tf.cast(label, tf.float32)\n",
    "        # fixed code (for almost all tfrec training)\n",
    "    dataset = tf.data.TFRecordDataset(recs)\n",
    "    dataset = dataset.map(_parser)\n",
    "    dataset = dataset.shuffle(128,reshuffle_each_iteration=True)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(BATCH_SIZE,drop_remainder=True)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.apply(tf.data.experimental.ignore_errors())\n",
    "    return dataset\n",
    "\n",
    "rec_dir=\"/home/ansary/WORK/Work/APSIS/datasets/Recognition/datasets/bw/temp/tfrecord/\"\n",
    "recs=[rec_path for rec_path in glob(os.path.join(rec_dir,\"*.tfrecord\"))]\n",
    "print(recs)\n",
    "ds=data_input_fn(recs,\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b67f801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------\n",
      "visualizing data\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"---------------------------------------------------------------\")\n",
    "print(\"visualizing data\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "for x,y in ds.take(1):\n",
    "    data=np.squeeze(x[\"image\"][0])\n",
    "    plt.imshow(data)\n",
    "    plt.show()\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "    print(\"label:\",x[\"label\"][0])\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "    print(\"pos:\",x[\"pos\"][0])\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "    print(\"mask:\",x[\"mask\"][0][0])\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "    print('Image Batch Shape:',x[\"image\"].shape)\n",
    "    print('Label Batch Shape:',x[\"label\"].shape)\n",
    "    print('Position Batch Shape:',x[\"pos\"].shape)\n",
    "    print('Mask Batch Shape:',x[\"mask\"].shape)\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "    print('Target Batch Shape:',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fc58b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in ds.take(1):\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81f46be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
